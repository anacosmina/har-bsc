{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train RGB model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"wcOgAqA7VER9","colab_type":"code","outputId":"47141f6a-f29b-41d2-e968-485b2dc6310b","executionInfo":{"status":"ok","timestamp":1552350627203,"user_tz":-120,"elapsed":57058,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 131323 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"PorLOCQvVQAm","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","root = '/content/drive/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m_F9Z0UrWRFt","colab_type":"code","outputId":"469921f0-4e59-45b9-b614-8db90e25d406","executionInfo":{"status":"ok","timestamp":1552350636629,"user_tz":-120,"elapsed":2249,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["import os\n","import h5py\n","import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras.models import Sequential\n","from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from numpy.random import permutation\n","from keras.optimizers import SGD\n","import pandas as pd\n","import datetime\n","import glob\n","import cv2\n","import math\n","import pickle\n","from collections import OrderedDict\n","from keras import backend as K"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"BMr6KQ8PtsGa","colab_type":"text"},"cell_type":"markdown","source":["Data set constants:"]},{"metadata":{"id":"NssBoNXDtrXr","colab_type":"code","outputId":"6a7e4f67-707d-405a-a83e-a8eaf3d11cd5","executionInfo":{"status":"ok","timestamp":1552350643022,"user_tz":-120,"elapsed":1090,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["activities = ['a' +  \"{:02d}\".format(x) for x in range(1, 17)]\n","print(activities)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['a01', 'a02', 'a03', 'a04', 'a05', 'a06', 'a07', 'a08', 'a09', 'a10', 'a11', 'a12', 'a13', 'a14', 'a15', 'a16']\n"],"name":"stdout"}]},{"metadata":{"id":"WyyVu5yLVJY5","colab_type":"text"},"cell_type":"markdown","source":["Source: https://github.com/yakzan/Human-Action-Recognition-with-Keras"]},{"metadata":{"id":"jaNk9wXamOed","colab_type":"code","colab":{}},"cell_type":"code","source":["weights_file = 'vgg16_weights.h5'\n","top_model_weights_file = 'fc_model.h5'\n","whole_model_weights_path = root + 'whole_model.h5'\n","\n","train_data_dir = root + 'msrda/msrda_rgb/train/'\n","test_data_dir = root + 'msrda/msrda_rgb/test/'\n","test_images_path = root + 'msrda/msrda_rgb/test/test/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Yh-NLpegpVOS","colab_type":"text"},"cell_type":"markdown","source":["Features of the data set:"]},{"metadata":{"id":"_ksaaRcjsjoQ","colab_type":"code","outputId":"add2c910-92bd-4a40-857a-efeb71fb5c9a","executionInfo":{"status":"ok","timestamp":1552350672807,"user_tz":-120,"elapsed":26108,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"cell_type":"code","source":["nb_test_samples = len(os.listdir(os.chdir(test_data_dir)))\n","\n","nb_train_samples = 0\n","for act in activities:\n","    nb_train_samples += len(os.listdir(os.chdir(train_data_dir + act)))\n","    \n","print(nb_test_samples)\n","print(nb_train_samples)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["601\n","1623\n"],"name":"stdout"}]},{"metadata":{"id":"FIv2R1B2y6rd","colab_type":"code","colab":{}},"cell_type":"code","source":["img_width, img_height = 640, 480\n","color_type_global = 3"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ciGr-FUVpOq7","colab_type":"code","colab":{}},"cell_type":"code","source":["# You can set a larger value here, according with the memory of your GPU.\n","batch_size = 16\n","nb_epoch = 100"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VHnAUtz802LC","colab_type":"text"},"cell_type":"markdown","source":["Load the weights of the pre-trained VGG16:"]},{"metadata":{"id":"_QA81xny90Gm","colab_type":"code","outputId":"bbc8f75a-e2a7-4e04-c501-f834908f058a","executionInfo":{"status":"ok","timestamp":1552350683971,"user_tz":-120,"elapsed":6226,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":120}},"cell_type":"code","source":["from keras.applications.vgg16 import VGG16\n","from keras.layers import Input\n","\n","model = VGG16(include_top=False, weights='imagenet')\n","image_input = Input(shape=(480, 640, 3), name='image_input')\n","output_vgg16_conv = model(image_input)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"23HHKaVeBmt3","colab_type":"text"},"cell_type":"markdown","source":["Add the fully-connected layers:"]},{"metadata":{"id":"zhKGizH9Bgzj","colab_type":"code","colab":{}},"cell_type":"code","source":["x = Flatten(name='flatten')(output_vgg16_conv)\n","x = Dense(4096, activation='relu', name='fc1')(x)\n","x = Dense(4096, activation='relu', name='fc2')(x)\n","x = Dense(16, activation='softmax', name='predictions')(x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rDJViBXTCebc","colab_type":"text"},"cell_type":"markdown","source":["Create own model:"]},{"metadata":{"id":"PEFE0Vp-CdnK","colab_type":"code","outputId":"f8d84143-1bfc-46da-f5fb-08c87d72349e","executionInfo":{"status":"ok","timestamp":1552350690503,"user_tz":-120,"elapsed":1948,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"cell_type":"code","source":["from keras.models import Model\n","\n","my_model = Model(input=image_input, output=x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"im..., outputs=Tensor(\"pr...)`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"metadata":{"id":"WjPfKKKz1UuN","colab_type":"code","outputId":"60a42cd1-4837-4d4f-e43e-24f130351103","executionInfo":{"status":"ok","timestamp":1552350693351,"user_tz":-120,"elapsed":752,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":334}},"cell_type":"code","source":["my_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","image_input (InputLayer)     (None, 480, 640, 3)       0         \n","_________________________________________________________________\n","vgg16 (Model)                multiple                  14714688  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 153600)            0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              629149696 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 16)                65552     \n","=================================================================\n","Total params: 660,711,248\n","Trainable params: 660,711,248\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"DhtvtzJHAXp2","colab_type":"code","colab":{}},"cell_type":"code","source":["# Set the first 15 layers to non-trainable (the original weights will not be updated).\n","for layer in my_model.layers[:15]:\n","    layer.trainable = False"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oHfoeqk2C63k","colab_type":"text"},"cell_type":"markdown","source":["Compile the model with a SGD/momentum optimizer:"]},{"metadata":{"id":"S-PX-lloC0T3","colab_type":"code","colab":{}},"cell_type":"code","source":["my_model.compile(loss = \"categorical_crossentropy\",\n","              optimizer=optimizers.SGD(lr=1e-6, momentum=0.9),\n","              metrics=['mean_squared_logarithmic_error', 'accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8csuJ5ibDMF-","colab_type":"text"},"cell_type":"markdown","source":["Data augmentation:"]},{"metadata":{"id":"AJTFbNxpDDb-","colab_type":"code","colab":{}},"cell_type":"code","source":["train_datagen = ImageDataGenerator(shear_range=0.3, zoom_range=0.3, rotation_range=0.3)\n","test_datagen = ImageDataGenerator()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"35zlBOmtDQ_1","colab_type":"text"},"cell_type":"markdown","source":["Training:"]},{"metadata":{"id":"c9LC1TkXDODy","colab_type":"code","outputId":"bdc2621e-e7b7-4533-af9b-ccbcb4a717f8","executionInfo":{"status":"ok","timestamp":1552350705373,"user_tz":-120,"elapsed":1330,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["train_generator = train_datagen.flow_from_directory(\n","        directory=train_data_dir,\n","        target_size=(img_height, img_width),\n","        batch_size=16,\n","        class_mode='categorical')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 1623 images belonging to 16 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"fbeIahiLFBdd","colab_type":"code","outputId":"ec41b0c1-acf4-4e95-ca8b-5aa25a178b6a","executionInfo":{"status":"ok","timestamp":1552350708256,"user_tz":-120,"elapsed":1324,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["class_dictionary = train_generator.class_indices\n","sorted_class_dictionary = OrderedDict(sorted(class_dictionary.items()))\n","sorted_class_dictionary = sorted_class_dictionary.values()\n","print(sorted_class_dictionary)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["odict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n"],"name":"stdout"}]},{"metadata":{"id":"KKqDZ-gTFNgB","colab_type":"text"},"cell_type":"markdown","source":["Fine-tuning the model:"]},{"metadata":{"id":"mD4nbyyLFKKG","colab_type":"code","outputId":"09be11dc-3ed0-48c3-acab-a5eff7f97359","executionInfo":{"status":"ok","timestamp":1552356238526,"user_tz":-120,"elapsed":4108813,"user":{"displayName":"Ana-Cosmina Popescu","photoUrl":"","userId":"13687164333845895082"}},"colab":{"base_uri":"https://localhost:8080/","height":472}},"cell_type":"code","source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=3, mode='min', verbose=1)\n","checkpoint = ModelCheckpoint('model_best_weights.h5', monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)\n","                             \n","my_model.fit_generator(\n","        train_generator,\n","        steps_per_epoch = int(nb_train_samples / batch_size),\n","        epochs = nb_epoch,\n","        validation_data = train_generator,\n","        validation_steps= int(nb_train_samples / batch_size),\n","        callbacks = [early_stop, checkpoint])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","101/101 [==============================] - 741s 7s/step - loss: 11.6961 - mean_squared_logarithmic_error: 0.0528 - acc: 0.0520 - val_loss: 11.6296 - val_mean_squared_logarithmic_error: 0.0523 - val_acc: 0.0510\n","\n","Epoch 00001: loss improved from inf to 11.69112, saving model to model_best_weights.h5\n","Epoch 2/100\n","101/101 [==============================] - 848s 8s/step - loss: 11.6417 - mean_squared_logarithmic_error: 0.0527 - acc: 0.0526 - val_loss: 11.5348 - val_mean_squared_logarithmic_error: 0.0522 - val_acc: 0.0554\n","\n","Epoch 00002: loss improved from 11.69112 to 11.64868, saving model to model_best_weights.h5\n","Epoch 3/100\n","101/101 [==============================] - 827s 8s/step - loss: 11.6415 - mean_squared_logarithmic_error: 0.0523 - acc: 0.0569 - val_loss: 11.6432 - val_mean_squared_logarithmic_error: 0.0519 - val_acc: 0.0641\n","\n","Epoch 00003: loss improved from 11.64868 to 11.64477, saving model to model_best_weights.h5\n","Epoch 4/100\n","101/101 [==============================] - 818s 8s/step - loss: 11.7274 - mean_squared_logarithmic_error: 0.0524 - acc: 0.0569 - val_loss: 11.7232 - val_mean_squared_logarithmic_error: 0.0527 - val_acc: 0.0523\n","\n","Epoch 00004: loss did not improve from 11.64477\n","Epoch 5/100\n","101/101 [==============================] - 310s 3s/step - loss: 11.7496 - mean_squared_logarithmic_error: 0.0519 - acc: 0.0675 - val_loss: 11.5822 - val_mean_squared_logarithmic_error: 0.0525 - val_acc: 0.0566\n","\n","Epoch 00005: loss did not improve from 11.64477\n","Epoch 6/100\n","101/101 [==============================] - 309s 3s/step - loss: 11.8498 - mean_squared_logarithmic_error: 0.0524 - acc: 0.0596 - val_loss: 11.5380 - val_mean_squared_logarithmic_error: 0.0521 - val_acc: 0.0572\n","\n","Epoch 00006: loss did not improve from 11.64477\n","Epoch 00006: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff1c06c5470>"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"slqUrkUdFVfo","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}